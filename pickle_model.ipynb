{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = []\n",
    "LABEL = []\n",
    "\n",
    "DIR_1 = 'Data/size_normalized_texts/fake/'\n",
    "LIST_1 = os.listdir(DIR_1)\n",
    "NUMBER_FILES = len(LIST_1)\n",
    "\n",
    "for i in range(NUMBER_FILES):\n",
    "    title = LIST_1[i]\n",
    "    LABEL.append(1)\n",
    "    with open(DIR_1 + title, 'r') as reader:\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        CORPUS.append(doc)\n",
    "\n",
    "DIR_0 = 'Data/size_normalized_texts/true/'\n",
    "LIST_0 = os.listdir(DIR_0)\n",
    "NUMBER_FILES = len(LIST_0)\n",
    "\n",
    "for i in range(NUMBER_FILES):\n",
    "    title = LIST_0[i]\n",
    "    LABEL.append(0)\n",
    "    with open(DIR_0 + title, 'r') as reader:\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        CORPUS.append(doc)\n",
    "\n",
    "assert len(CORPUS) == len(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_and_df(corpus, label):\n",
    "    \"\"\"\n",
    "    creates vectors for articles/news and returns dataframe with news\n",
    "    as word vectors indexed by 1(Fake) or 0(Not Fake).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : Trained scikit-learn model pipeline.\n",
    "    label : str\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    dataframe, vectorized corpus\n",
    "    \"\"\"\n",
    "\n",
    "    cv = TfidfVectorizer()\n",
    "    cv.fit(corpus)\n",
    "    corpus_vecs = cv.transform(corpus)\n",
    "\n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=label,\n",
    "                        columns=cv.get_feature_names()), cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME, CV = vectors_and_df(CORPUS, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=20000000.0, max_iter=300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = DATAFRAME\n",
    "Y = DATAFRAME.index\n",
    "\n",
    "LRM = LogisticRegression(C=2e7, max_iter=300)\n",
    "LRM.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file in the current working directory\n",
    "pkl_filename = \"flask-app/logistic_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(LRM, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open(\"flask-app/logistic_model.pkl\", 'rb') as file:\n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 91.04 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score and predict target values\n",
    "score = pickle_model.score(Xtest, ytest)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "Ypredict = pickle_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle fitted cv.TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file in the current working directory\n",
    "pkl_filename = \"flask-app/CVfitted.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(CV, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
